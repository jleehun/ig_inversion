{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ig_pkg.datasets import get_datasets\n",
    "\n",
    "from ig_pkg.models.generator import get_model\n",
    "from ig_pkg.models.classifier import get_classifier\n",
    "from ig_pkg.models.pretrained_models import get_pretrained_model\n",
    "\n",
    "from ig_pkg.inputattribs.ig import make_interpolation, ig\n",
    "from ig_pkg.inputattribs.baseline_generator import get_baseline_generator\n",
    "\n",
    "from ig_pkg.misc import process_heatmap, normalize_tensor, convert_to_img, convert_mask_img, label_to_class, tran, na_imshow\n",
    "\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ig_pkg.loss.focal_loss import FocalLoss\n",
    "from ig_pkg.loss.metrics import ArcMarginProduct, AddMarginProduct\n",
    "\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "my_cmap=plt.cm.seismic(np.arange(plt.cm.seismic.N))\n",
    "device = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "CIFAR10_STATS = {\n",
    "    'mean' : [0.4914, 0.4822, 0.4465],\n",
    "    'std' : [0.2023, 0.1994, 0.2010]\n",
    "}\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(), \n",
    "                T.Normalize(CIFAR10_STATS['mean'], CIFAR10_STATS['std'])\n",
    "            ])\n",
    "\n",
    "valid_dataset = torchvision.datasets.CIFAR10(root='/data8/donghun/cifar10/untracked/', train=False, transform=transform)\n",
    "# valid_dataset = torchvision.datasets.CIFAR10(root='/root/data/cifar10', train=False, transform=transform)\n",
    "# interpolation = torch.from_numpy(np.load('/root/results/cifar10/image_simple_gradient_ascent_interpolation.npy'))\n",
    "\n",
    "# interpolation.shape\n",
    "model = torch.jit.load(\"/data8/donghun/cifar10/results/densenet/script_model.pt\",  map_location='cpu').eval().to(device)\n",
    "# classifier = torch.jit.load(\"/root/data/cifar10/cifar10/results/densenet/script_model.pt\",  map_location='cpu').eval().to('cuda:0')\n",
    "\n",
    "# ae = torch.jit.load(\"/root/data/cifar10/cifar10/results/ae/script_model.pt\",  map_location='cpu').eval().to('cuda:0')\n",
    "# bottle = torch.load(\"/root/ig_inversion/results/bottleneck_ae/results/model_best.pt\",  map_location='cpu').eval().to('cuda:0')\n",
    "\n",
    "bottleneck = torch.load(\"/home/dhlee/code/ig_inversion/ig_pkg/bottleneck_ae/results/cifar10_8/model_best.pt\",  map_location='cpu').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(-1, 1, 5)\n",
    "b = np.linspace(-1, 1, 5)\n",
    "\n",
    "dots = []\n",
    "for i in a:\n",
    "    for j in b:\n",
    "        dots.append(torch.tensor([i, j],  dtype=torch.float32, device=device).unsqueeze(0))\n",
    "# dots\n",
    "\n",
    "new = []\n",
    "dot = torch.stack(dots)\n",
    "# dot.shape\n",
    "for i in dot:\n",
    "    i = i.to(device)\n",
    "    new.append(bottleneck.decode(i).squeeze(0))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new = torch.stack(new)\n",
    "# print(new.shape)\n",
    "torch.save(new, '/home/dhlee/code/ig_inversion/results/baseline/cifar10_baseline_2.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# bottleneck = torch.load(\"/home/dhlee/code/ig_inversion/ig_pkg/bottleneck_ae/results/cifar10_8/model_best.pt\",  map_location='cpu').eval().to(device)\n",
    "latent = []\n",
    "for i in tqdm(valid_dataset):\n",
    "    input, label = i\n",
    "    input = input.to(device)    \n",
    "    x_hat, loss_dict, info = bottleneck(input.unsqueeze(0))\n",
    "    latent.append(info['bottleneck'])\n",
    "    # print(info['bottleneck'].shape)\n",
    "    # print(x_hat.shape)\n",
    "    # print(latent['bottleneck'].shape)\n",
    "    # if i ==2: break\n",
    "latent = torch.stack(latent)\n",
    "# print(latent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# latent = torch.stack(latent)\n",
    "# len(latent)\n",
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.load('/home/dhlee/code/ig_inversion/results/baseline/cifar10_baseline_2.pt')\n",
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of PCA(n_components=2)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "num = latent.clone().detach().cpu().numpy()\n",
    "num = num.reshape(-1, 8)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy': True,\n",
       " 'iterated_power': 'auto',\n",
       " 'n_components': 2,\n",
       " 'n_oversamples': 10,\n",
       " 'power_iteration_normalizer': 'auto',\n",
       " 'random_state': None,\n",
       " 'svd_solver': 'auto',\n",
       " 'tol': 0.0,\n",
       " 'whiten': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.get_params(['deep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01552928,  0.571816  , -0.03334171, -0.40915   ,  0.1417619 ,\n",
       "         0.08252704,  0.2810632 , -0.63116264],\n",
       "       [-0.06604326, -0.18297149,  0.04879477,  0.7596098 , -0.00115259,\n",
       "        -0.06883926,  0.28585574, -0.544351  ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# latent1, latent2 = pca.components_\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "b = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "\n",
    "new_latent = []\n",
    "for i in a:\n",
    "    for j in b:\n",
    "        temp = i * latent1 + j * latent2\n",
    "        new_latent.append(torch.tensor(temp))\n",
    "# for \n",
    "# latent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 8])\n"
     ]
    }
   ],
   "source": [
    "new_st = torch.stack(new_latent)\n",
    "print(new_st.shape)\n",
    "# new_latent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 3, 32, 32])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c = torch.zeros((1, 2))\n",
    "ch = bottleneck.decode(new_st.to(device))\n",
    "ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ch, '/home/dhlee/code/ig_inversion/results/baseline/cifar10_baseline_8.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
