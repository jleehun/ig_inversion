{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ig_pkg.datasets import get_datasets\n",
    "\n",
    "from ig_pkg.models.generator import get_model\n",
    "from ig_pkg.models.classifier import get_classifier\n",
    "from ig_pkg.models.pretrained_models import get_pretrained_model\n",
    "\n",
    "from ig_pkg.inputattribs.ig import make_interpolation, ig\n",
    "from ig_pkg.inputattribs.baseline_generator import get_baseline_generator\n",
    "\n",
    "from ig_pkg.misc import process_heatmap, normalize_tensor, convert_to_img, convert_mask_img, label_to_class, tran, na_imshow\n",
    "\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ig_pkg.loss.focal_loss import FocalLoss\n",
    "from ig_pkg.loss.metrics import ArcMarginProduct, AddMarginProduct\n",
    "\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "my_cmap=plt.cm.seismic(np.arange(plt.cm.seismic.N))\n",
    "device = 'cuda:7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as T\n",
    "# CIFAR10_STATS = {\n",
    "#     'mean' : [0.4914, 0.4822, 0.4465],\n",
    "#     'std' : [0.2023, 0.1994, 0.2010]\n",
    "# }\n",
    "\n",
    "# transform = T.Compose([\n",
    "#                 T.ToTensor(), \n",
    "#                 T.Normalize(CIFAR10_STATS['mean'], CIFAR10_STATS['std'])\n",
    "#             ])\n",
    "\n",
    "# valid_dataset = torchvision.datasets.CIFAR10(root='/data8/donghun/cifar10/untracked/', train=False, transform=transform)\n",
    "# valid_dataset = torchvision.datasets.CIFAR10(root='/root/data/cifar10', train=False, transform=transform)\n",
    "# interpolation = torch.from_numpy(np.load('/root/results/cifar10/image_simple_gradient_ascent_interpolation.npy'))\n",
    "\n",
    "# interpolation.shape\n",
    "# model = torch.jit.load(\"/data8/donghun/cifar10/results/densenet/script_model.pt\",  map_location='cpu').eval().to(device)\n",
    "# classifier = torch.jit.load(\"/root/data/cifar10/cifar10/results/densenet/script_model.pt\",  map_location='cpu').eval().to('cuda:0')\n",
    "\n",
    "# ae = torch.jit.load(\"/root/data/cifar10/cifar10/results/ae/script_model.pt\",  map_location='cpu').eval().to('cuda:0')\n",
    "# bottle = torch.load(\"/root/ig_inversion/results/bottleneck_ae/results/model_best.pt\",  map_location='cpu').eval().to('cuda:0')\n",
    "\n",
    "bottleneck = torch.load(\"/home/dhlee/code/ig_inversion/ig_pkg/bottleneck_ae/results/cifar10_8/model_best.pt\",  map_location='cpu').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.9790, -0.5944,  0.9840,  0.3247, -0.9923, -0.8754, -0.6798,  0.6908]]),\n",
       " tensor([[ 0.9657, -0.4447,  0.9570,  0.1508, -0.9633, -0.8206, -0.5215,  0.3061]]),\n",
       " tensor([[-0.0722, -0.1693,  0.1727, -0.0027,  0.0215, -0.0958, -0.0955, -0.0293]]),\n",
       " tensor([[ 0.9618, -0.3241,  0.8949,  0.0161, -0.7720, -0.8048, -0.1046, -0.4961]]),\n",
       " tensor([[ 0.9800, -0.0379,  0.8815, -0.1404, -0.6166, -0.8239,  0.1591, -0.8084]])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_baseline = []\n",
    "latent_baseline = []\n",
    "coeff = [-1, -0.5, 0, 0.5, 1]\n",
    "for i in range(5):\n",
    "    temp = torch.ones((3, 32, 32)) * coeff[i]\n",
    "    # print(torch.mean(temp))\n",
    "    image_baseline.append(temp)\n",
    "    t1, t2 = bottleneck.encode(temp.unsqueeze(0).to(device))\n",
    "    # print(t1)\n",
    "    latent_baseline.append(t1.detach().cpu())\n",
    "latent_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9790, -0.5944,  0.9840,  0.3247, -0.9923, -0.8754, -0.6798,  0.6908])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_hat, loss_dict, info = bottleneck(temp.unsqueeze(0).to(device))\n",
    "# info['bottleneck']\n",
    "# info\n",
    "latent_baseline[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01552928,  0.571816  , -0.03334171, -0.40915   ,  0.1417619 ,\n",
       "         0.08252704,  0.2810632 , -0.63116264],\n",
       "       [-0.06604326, -0.18297149,  0.04879477,  0.7596098 , -0.00115259,\n",
       "        -0.06883926,  0.28585574, -0.544351  ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent1, latent2 = [ 0.01552928,  0.571816  , -0.03334171, -0.40915   ,  0.1417619 ,\n",
    "         0.08252704,  0.2810632 , -0.63116264], [-0.06604326, -0.18297149,  0.04879477,  0.7596098 , -0.00115259,\n",
    "        -0.06883926,  0.28585574, -0.544351  ]\n",
    "\n",
    "latent = np.array([latent1, latent2])\n",
    "latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3303247 -0.1702153]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'numpy.float64'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m ans \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mlstsq(latent\u001b[39m.\u001b[39mT, temp1, rcond\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(ans)\n\u001b[0;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(latent1 \u001b[39m*\u001b[39;49m ans[\u001b[39m0\u001b[39;49m] \u001b[39m+\u001b[39m latent2 \u001b[39m*\u001b[39m ans[\u001b[39m1\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(temp1)\n\u001b[1;32m      9\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'numpy.float64'"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    temp1= latent_baseline[i][0]\n",
    "    temp1 = np.array(temp1)\n",
    "        \n",
    "    ans = np.linalg.lstsq(latent.T, temp1, rcond=None)[0]\n",
    "    print(ans)\n",
    "    print(latent1 * ans[0] + latent2 * ans[1])\n",
    "    print(temp1)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.009417411250020699, -0.7295564009362563, 0.03604968379139997, 0.41500513873858386, -0.18839316860040162, -0.09807026422045734, -0.42256233851853287, 0.9323081198983701]\n",
      "[ 0.978988   -0.5943823   0.9840166   0.32468495 -0.99229264 -0.8753998\n",
      " -0.6797708   0.69082797]\n"
     ]
    }
   ],
   "source": [
    "def mul_float(list1, list2, coeff):\n",
    "    ans = []\n",
    "    for i in range(len(list1)):\n",
    "        t1 = list1[i]\n",
    "        t2 = list2[i]\n",
    "        \n",
    "        c = t1 * coeff[0] + t2 * coeff[1]\n",
    "        ans.append(c)\n",
    "        \n",
    "    return ans\n",
    "\n",
    "print(mul_float(latent1, latent2, ans))\n",
    "print(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(latent1 \u001b[39m*\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1.33\u001b[39;49m \u001b[39m+\u001b[39m latent2 \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m0.17\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(temp1)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "print(latent1 * -1.33 + latent2 * -0.17)\n",
    "print(temp1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(-1, 1, 5)\n",
    "b = np.linspace(-1, 1, 5)\n",
    "\n",
    "dots = []\n",
    "for i in a:\n",
    "    for j in b:\n",
    "        dots.append(torch.tensor([i, j],  dtype=torch.float32, device=device).unsqueeze(0))\n",
    "# dots\n",
    "\n",
    "new = []\n",
    "dot = torch.stack(dots)\n",
    "# dot.shape\n",
    "for i in dot:\n",
    "    i = i.to(device)\n",
    "    new.append(bottleneck.decode(i).squeeze(0))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new = torch.stack(new)\n",
    "# print(new.shape)\n",
    "torch.save(new, '/home/dhlee/code/ig_inversion/results/baseline/cifar10_baseline_2.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "bottleneck = torch.load(\"/home/dhlee/code/ig_inversion/ig_pkg/bottleneck_ae/results/cifar10_8/model_best.pt\",  map_location='cpu').eval().to(device)\n",
    "latent = []\n",
    "for i in tqdm(valid_dataset):\n",
    "    input, label = i\n",
    "    input = input.to(device)    \n",
    "    x_hat, loss_dict, info = bottleneck(input.unsqueeze(0))\n",
    "    latent.append(info['bottleneck'])\n",
    "    # print(info['bottleneck'].shape)\n",
    "    # print(x_hat.shape)\n",
    "    # print(latent['bottleneck'].shape)\n",
    "    # if i ==2: break\n",
    "latent = torch.stack(latent)\n",
    "# print(latent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# latent = torch.stack(latent)\n",
    "# len(latent)\n",
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.load('/home/dhlee/code/ig_inversion/results/baseline/cifar10_baseline_2.pt')\n",
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of PCA(n_components=2)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "num = latent.clone().detach().cpu().numpy()\n",
    "num = num.reshape(-1, 8)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy': True,\n",
       " 'iterated_power': 'auto',\n",
       " 'n_components': 2,\n",
       " 'n_oversamples': 10,\n",
       " 'power_iteration_normalizer': 'auto',\n",
       " 'random_state': None,\n",
       " 'svd_solver': 'auto',\n",
       " 'tol': 0.0,\n",
       " 'whiten': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.get_params(['deep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01552928,  0.571816  , -0.03334171, -0.40915   ,  0.1417619 ,\n",
       "         0.08252704,  0.2810632 , -0.63116264],\n",
       "       [-0.06604326, -0.18297149,  0.04879477,  0.7596098 , -0.00115259,\n",
       "        -0.06883926,  0.28585574, -0.544351  ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# latent1, latent2 = pca.components_\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "b = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "\n",
    "new_latent = []\n",
    "for i in a:\n",
    "    for j in b:\n",
    "        temp = i * latent1 + j * latent2\n",
    "        new_latent.append(torch.tensor(temp))\n",
    "# for \n",
    "# latent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 8])\n"
     ]
    }
   ],
   "source": [
    "new_st = torch.stack(new_latent)\n",
    "print(new_st.shape)\n",
    "# new_latent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 3, 32, 32])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c = torch.zeros((1, 2))\n",
    "ch = bottleneck.decode(new_st.to(device))\n",
    "ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ch, '/home/dhlee/code/ig_inversion/results/baseline/cifar10_baseline_8.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
