{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ig_pkg.datasets import get_datasets\n",
    "\n",
    "from ig_pkg.models.generator import get_model\n",
    "from ig_pkg.models.classifier import get_classifier\n",
    "from ig_pkg.models.pretrained_models import get_pretrained_model\n",
    "\n",
    "from ig_pkg.inputattribs.ig import ig\n",
    "from ig_pkg.inputattribs.baseline_generator import get_baseline_generator\n",
    "\n",
    "from ig_pkg.misc import process_heatmap, normalize_tensor, convert_to_img, label_to_class, tran, na_imshow\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path=\"/root/data/ILSVRC2012_val/\"\n",
    "\n",
    "# _, valid_datasets = get_datasets(\"imagenet1k\", data_path)\n",
    "# _, valid_datasets2 = get_datasets(\"imagenet1k\", data_path, transform=T.Compose([T.Resize(256),T.CenterCrop(256),]) )\n",
    "\n",
    "device=\"cuda:0\"\n",
    "# model = get_pretrained_model(\"vgg16\").to(device)\n",
    "\n",
    "# train_dataset, valid_dataset = get_datasets(name= 'celebAHQ_identity', data_path = '/root/data/CelebA_HQ_facial_identity_dataset')\n",
    "# class_names = train_dataset.classes\n",
    "# np.save('/root/data/celebAHQ_identity_class_names.npy', class_names)\n",
    "# class_names = np.load('/root/data/celebAHQ_identity_class_names.npy')\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "# test_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "# image_path = '/root/data/CelebA_HQ_facial_identity_dataset/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ig_pkg.loss.focal_loss import FocalLoss\n",
    "from ig_pkg.loss.metrics import ArcMarginProduct, AddMarginProduct\n",
    "import torchvision.models as models\n",
    "\n",
    "device=\"cuda:0\"\n",
    "train_dataset, valid_dataset = get_datasets(name= 'celebAHQ_whole', data_path = '/root/data/whole') # 3819,2398 \n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features # 512\n",
    "model.fc = nn.Linear(num_features, 3819) # multi-class classification (num_of_class == 307)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 30\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "\n",
    "    # load a batch data of images\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "\n",
    "save_path = f'/root/pretrained/celebahq_whole_{epoch_acc}.pth'\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #0] Loss: 7.2841 Acc: 1.9056% Time: 103.2269s\n",
      "[Train #1] Loss: 5.3779 Acc: 14.7313% Time: 200.3553s\n",
      "[Train #2] Loss: 3.7013 Acc: 35.2106% Time: 296.9381s\n",
      "[Train #3] Loss: 2.3991 Acc: 57.8945% Time: 394.6895s\n",
      "[Train #4] Loss: 1.4377 Acc: 77.4545% Time: 491.7799s\n",
      "[Train #5] Loss: 0.7544 Acc: 91.3602% Time: 589.7661s\n",
      "[Train #6] Loss: 0.3378 Acc: 97.9025% Time: 687.1586s\n",
      "[Train #7] Loss: 0.1383 Acc: 99.6341% Time: 783.9427s\n",
      "[Train #8] Loss: 0.0699 Acc: 99.8393% Time: 880.5901s\n",
      "[Train #9] Loss: 0.0476 Acc: 99.8661% Time: 979.0721s\n",
      "[Train #10] Loss: 0.0416 Acc: 99.8304% Time: 1076.6075s\n",
      "[Train #11] Loss: 0.0305 Acc: 99.8974% Time: 1173.7527s\n",
      "[Train #12] Loss: 0.0257 Acc: 99.9018% Time: 1271.6747s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ig_pkg.loss.focal_loss import FocalLoss\n",
    "from ig_pkg.loss.metrics import ArcMarginProduct, AddMarginProduct\n",
    "import torchvision.models as models\n",
    "\n",
    "device=\"cuda:0\"\n",
    "train_dataset, valid_dataset = get_datasets(name= 'celebAHQ_5', data_path = '/root/data/train') # 3819,2398 \n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features # 512\n",
    "model.fc = nn.Linear(num_features, 2398) # multi-class classification (num_of_class == 307)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 30\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "\n",
    "    # load a batch data of images\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "    if epoch_acc > 99.9: break\n",
    "        \n",
    "save_path = f'/root/pretrained/celebahq_train_{epoch_acc}.pth'\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/dh/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/dh/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #0] Loss: 8.1924 Acc: 1.0633% Time: 133.8641s\n",
      "[Train #1] Loss: 6.5828 Acc: 8.9867% Time: 270.5878s\n",
      "[Train #2] Loss: 5.1467 Acc: 23.5567% Time: 410.5533s\n",
      "[Train #3] Loss: 3.9258 Acc: 39.5900% Time: 550.8081s\n",
      "[Train #4] Loss: 2.9015 Acc: 55.1833% Time: 690.3970s\n",
      "[Train #5] Loss: 2.0580 Acc: 68.9933% Time: 831.7129s\n",
      "[Train #6] Loss: 1.3593 Acc: 81.0033% Time: 969.8034s\n",
      "[Train #7] Loss: 0.8327 Acc: 89.6933% Time: 1108.4917s\n",
      "[Train #8] Loss: 0.4637 Acc: 95.1233% Time: 1248.7256s\n",
      "[Train #9] Loss: 0.2327 Acc: 98.8367% Time: 1383.8723s\n",
      "[Train #10] Loss: 0.1083 Acc: 99.7600% Time: 1523.6631s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ig_pkg.loss.focal_loss import FocalLoss\n",
    "from ig_pkg.loss.metrics import ArcMarginProduct, AddMarginProduct\n",
    "import torchvision.models as models\n",
    "\n",
    "device=\"cuda:0\"\n",
    "train_dataset, valid_dataset = get_datasets(name= 'celebAHQ_5', data_path = '/root/data/identity_celebahq') # 3819,2398 \n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "# np.save('/root/data/celebahq_identity/identity_original.npy', class_names)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features # 512\n",
    "model.fc = nn.Linear(num_features, 6217) \n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 30\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "\n",
    "    # load a batch data of images\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "    if epoch_acc > 99: break\n",
    "        \n",
    "save_path = f'/root/pretrained/celebahq_original_{epoch_acc}.pth'\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "torch.Size([15, 3, 224, 224])\n",
      "torch.Size([15])\n",
      "torch.Size([15])\n",
      "1215\n",
      "[Test #29] Loss: 2.4216 Acc: 49.2181% Time: 1565.9302s\n"
     ]
    }
   ],
   "source": [
    "# model = get_classifier('resnet', 'data').to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "    i = 0\n",
    "    for inputs, labels in test_dataloader:\n",
    "        i += 1\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)        \n",
    "                    \n",
    "        outputs = model(inputs)\n",
    "        outputs = metric_fc(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    print(i)\n",
    "    print(inputs.size())\n",
    "    print(labels.size())\n",
    "    print(preds.size())\n",
    "    print(len(valid_dataset))\n",
    "    epoch_loss = running_loss / len(valid_dataset)\n",
    "    epoch_acc = running_corrects / len(valid_dataset) * 100.\n",
    "    print('[Test #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Loss: 0.5880 Acc: 86.0082% Time: 5.7431s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "\n",
    "model = get_classifier('resnet', 'data')\n",
    "model = model.to(\"cuda:0\")\n",
    "device=\"cuda:0\"\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.eval()\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(test_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#         if i == 0:\n",
    "#             print('[Prediction Result Examples]')\n",
    "#             images = torchvision.utils.make_grid(inputs[:4])\n",
    "#             na_imshow(images.cpu(), title=[class_names[x] for x in labels[:4]])\n",
    "#             images = torchvision.utils.make_grid(inputs[4:8])\n",
    "#             na_imshow(images.cpu(), title=[class_names[x] for x in labels[4:8]])\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_dataset)\n",
    "    epoch_acc = running_corrects / len(valid_dataset) * 100.\n",
    "    print('[Test] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch_loss, epoch_acc, time.time() - start_time))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen = get_model('stylegan', '/root/pretrained/stylegan-celebahq-1024x1024.pt', 1024)\n",
    "gen = get_model('stylegan', '/root/pretrained/stylegan-celebahq-1024x1024.pt', 1024)\n",
    "gen = gen.to('cuda:0')\n",
    "\n",
    "latent = torch.rand((3, 512)).to(\"cuda:0\")\n",
    "images = gen(latent)\n",
    "\n",
    "classifier = get_classifier('resnet', 'data')\n",
    "classifier = classifier.to(\"cuda:0\")\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.Resize(224),\n",
    "                T.CenterCrop(224),\n",
    "                tran,\n",
    "                T.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "            ])\n",
    "img = transform(images)\n",
    "\n",
    "score = classifier(img)\n",
    "label = torch.argmax(score, dim = 1)\n",
    "pred = label_to_class(label, class_names)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [0.5, 0.5, 0.5]\n",
    "STD = [0.5, 0.5, 0.5]\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "CIFAR100_MEAN = [0.4914, 0.4822, 0.4465]\n",
    "CIFAR100_STD  = [0.2023, 0.1994, 0.2010] \n",
    "\n",
    "CIFAR10_MEAN = [0.4914, 0.4822, 0.4465]\n",
    "CIFAR10_STD  = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "MNIST_MEAN = [0.1307]\n",
    "MNIST_STD  = [0.3081] \n",
    "\n",
    "temp = img[0].detach().cpu()\n",
    "def na_imshow(input, mean, std):\n",
    "#     input = input.numpy()\n",
    "#     print(input.shape)\n",
    "    input = input.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "    input = std * input + mean\n",
    "    input = np.clip(input, 0, 1)\n",
    "#     input[:, :, 0] += 0.1\n",
    "#     input = input.permute\n",
    "    plt.figure()\n",
    "    plt.imshow(input)\n",
    "    plt.show()   \n",
    "    \n",
    "# na_imshow(temp, MEAN, STD)\n",
    "na_imshow(temp, IMAGENET_MEAN, IMAGENET_STD)\n",
    "# na_imshow(temp, CIFAR100_MEAN, CIFAR100_STD)\n",
    "# na_imshow(temp, CIFAR10_MEAN, CIFAR10_STD)\n",
    "# na_imshow(temp, MNIST_MEAN, MNIST_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize = (15, 4))\n",
    "axes = axes.flat\n",
    "\n",
    "for i in range(len(cls)):\n",
    "    ax = next(axes)\n",
    "    x = img[i]    \n",
    "    imga = convert_to_img(x)\n",
    "    ax.imshow(imga)\n",
    "    tlt = cls[i]\n",
    "    ax.set_title(tlt)\n",
    "    \n",
    "image_path = '/root/data/CelebA_HQ_facial_identity_dataset/train'\n",
    "\n",
    "\n",
    "for i in range(len(cls)):\n",
    "    img_directory = os.path.join(image_path, cls[i])    \n",
    "    img_path_list = os.listdir(img_directory)\n",
    "    img_path = os.path.join(img_directory, img_path_list[0])\n",
    "#     print(img_path)\n",
    "    im = Image.open(img_path)\n",
    "    \n",
    "    ax = next(axes)\n",
    "    ax.imshow(im)    \n",
    "\n",
    "plt.savefig('/root/ig_inversion/figure/baseline/1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh",
   "language": "python",
   "name": "dh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
