{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AJbOdjZd4Qq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ig_pkg.datasets import get_datasets\n",
    "\n",
    "from ig_pkg.models.generator import get_model\n",
    "from ig_pkg.models.classifier import get_classifier\n",
    "from ig_pkg.models.pretrained_models import get_pretrained_model\n",
    "\n",
    "from ig_pkg.inputattribs.ig import make_interpolation, ig\n",
    "from ig_pkg.inputattribs.baseline_generator import get_baseline_generator\n",
    "\n",
    "from ig_pkg.misc import process_heatmap, normalize_tensor, convert_to_img, convert_mask_img, label_to_class, tran, na_imshow\n",
    "\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ig_pkg.loss.focal_loss import FocalLoss\n",
    "from ig_pkg.loss.metrics import ArcMarginProduct, AddMarginProduct\n",
    "\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "my_cmap=plt.cm.seismic(np.arange(plt.cm.seismic.N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/PAIR-code/saliency/blob/master/Examples_pytorch.ipynb\n",
    "\n",
    "import saliency.core as saliency\n",
    "\n",
    "# Boilerplate methods.\n",
    "def ShowImage(im, title='', ax=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(im)\n",
    "    plt.title(title)\n",
    "\n",
    "def ShowGrayscaleImage(im, title='', ax=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(im, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "    plt.title(title)\n",
    "\n",
    "def ShowHeatMap(im, title, ax=None):\n",
    "    if ax is None:\n",
    "        P.figure()\n",
    "    P.axis('off')\n",
    "    P.imshow(im, cmap='inferno')\n",
    "    P.title(title)\n",
    "\n",
    "transformer = T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean = IMAGENET_MEAN, std = IMAGENET_STD),\n",
    "])\n",
    "\n",
    "def LoadNumpy(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    im = im.resize((224, 224)) # reserve channel \n",
    "    im = np.asarray(im)\n",
    "    return im    \n",
    "\n",
    "# def PreprocessImages(images):\n",
    "#     # assumes input is 4-D, with range [0,255]\n",
    "#     #\n",
    "#     # torchvision have color channel as first dimension\n",
    "#     # with normalization relative to mean/std of ImageNet:\n",
    "#     #    https://pytorch.org/vision/stable/models.html\n",
    "#     images = np.array(images)\n",
    "#     images = images/255\n",
    "#     images = np.transpose(images, (0,3,1,2))\n",
    "#     images = torch.tensor(images, dtype=torch.float32)\n",
    "#     images = transformer.forward(images)\n",
    "#     return images.requires_grad_(True)\n",
    "\n",
    "def LoadTensor(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    temp = np.asarray(im)\n",
    "#     if len(temp.shape) == 3: images = transformer(im)    \n",
    "#     else: return None\n",
    "    \n",
    "    images = transformer(im)    \n",
    "    return images.requires_grad_(True)\n",
    "\n",
    "class_idx_str = 'class_idx_str'\n",
    "def call_model_function(images, call_model_args=None, expected_keys=None):\n",
    "    images = PreprocessImages(images)\n",
    "    target_class_idx =  call_model_args[class_idx_str]\n",
    "    output = model(images)\n",
    "    m = torch.nn.Softmax(dim=1)\n",
    "    output = m(output)\n",
    "    if saliency.base.INPUT_OUTPUT_GRADIENTS in expected_keys:\n",
    "        outputs = output[:,target_class_idx]\n",
    "        grads = torch.autograd.grad(outputs, images, grad_outputs=torch.ones_like(outputs))\n",
    "        grads = torch.movedim(grads[0], 1, 3)\n",
    "        gradients = grads.detach().numpy()\n",
    "        return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n",
    "    else:\n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[:,target_class_idx] = 1\n",
    "        model.zero_grad()\n",
    "        output.backward(gradient=one_hot, retain_graph=True)\n",
    "        return conv_layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/root/data/ILSVRC2012_val/\"\n",
    "\n",
    "_, valid_datasets = get_datasets(\"imagenet1k\", data_path)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_datasets, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "model = models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "eval_mode = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n02443484: 40 black-footed_ferret\n",
    "# n01614925: 398 bald_eagle\n",
    "\n",
    "data_path=\"/root/data/ILSVRC2012_val/\"\n",
    "\n",
    "ferrot_dir = os.path.join(data_path, 'val', 'n02443484')\n",
    "ferrot_idx = os.listdir(ferrot_dir)[1]\n",
    "ferrot_np = LoadNumpy(os.path.join(ferrot_dir, ferrot_idx))\n",
    "ferrot_tensor = LoadTensor(os.path.join(ferrot_dir, ferrot_idx))\n",
    "\n",
    "# eagle_dir = os.path.join(data_path, 'val', 'n01614925')\n",
    "# eagle_idx = os.listdir(eagle_dir)[1]\n",
    "# eagle_img = LoadNumpy(os.path.join(eagle_dir, eagle_idx))\n",
    "# eagle_tensor = LoadTensor(os.path.join(eagle_dir, eagle_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "names = {\n",
    "    'zero',\n",
    "    'one',\n",
    "    'min',\n",
    "    'max',\n",
    "    'scalar',\n",
    "#     'encoder',\n",
    "#     'optimizer',\n",
    "#     'hybrid',\n",
    "    'gaussian_blur',\n",
    "    'gaussian',\n",
    "    'uniform',\n",
    "    'maximumdistance' \n",
    "}\n",
    "\n",
    "# {'gaussian',\n",
    "#  'gaussian_blur',\n",
    "#  'max',\n",
    "#  'maximumdistance',\n",
    "#  'min',\n",
    "#  'one',\n",
    "#  'scalar',\n",
    "#  'uniform',\n",
    "#  'zero'}\n",
    "\n",
    "index = 0 \n",
    "# x,y = valid_datasets[index]\n",
    "x = ferrot_tensor\n",
    "y = 359\n",
    "\n",
    "fig, axes = plt.subplots(2, (len(names)//2)+1, figsize=(2*len(names)//2, 2*2))\n",
    "axes_flat = axes.flat \n",
    "my_cmap=plt.cm.seismic(np.arange(plt.cm.seismic.N))\n",
    "\n",
    "ax = next(axes_flat)\n",
    "ax.imshow(convert_to_img(x))\n",
    "\n",
    "AOPC = []\n",
    "LODDs = []\n",
    "Kendal = []\n",
    "for name in names:\n",
    "    print(name)\n",
    "    a = []\n",
    "    b = []\n",
    "    try:\n",
    "        b_generator =  get_baseline_generator(name, scalar = 0.3)\n",
    "        baseline = b_generator(x=x,y=y)\n",
    "\n",
    "    except Exception as e: \n",
    "        print(\"-----\")\n",
    "        print(\"fail:\", name)\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "    attr = ig(eval_mode.to(device), x, y, baseline, device=device)\n",
    "    Kendal.append(kendal_correlation(eval_mode, ferrot_tensor, baseline, attr.detach().cpu().numpy(), device))\n",
    "\n",
    "#     print(name)\n",
    "    for i in range(19):\n",
    "#         k = i * 5 + 5        \n",
    "        k = i + 1\n",
    "        aopc, lodds = pipeline(eval_mode, ferrot_tensor.to(device), baseline, attr, k, device, name)\n",
    "        \n",
    "#         print(name, k, aopc, lodds)\n",
    "        a.append(aopc)\n",
    "        b.append(lodds)\n",
    "    \n",
    "    attr, kwargs  = process_heatmap(attr.cpu(), my_cmap)\n",
    "    ax = next(axes_flat)\n",
    "    ax.imshow(attr, **kwargs)\n",
    "    ax.set_title(name)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    AOPC.append(a)\n",
    "    LODDs.append(b)    \n",
    "    \n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMy8G3IL+8++WTZ/K7SQBqo",
   "collapsed_sections": [],
   "name": "CelebAMask HQ Dataset Processing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dh",
   "language": "python",
   "name": "dh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
