{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4AJbOdjZd4Qq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ig_pkg.datasets import get_datasets\n",
    "\n",
    "from ig_pkg.models.generator import get_model\n",
    "from ig_pkg.models.classifier import get_classifier\n",
    "from ig_pkg.models.pretrained_models import get_pretrained_model\n",
    "\n",
    "from ig_pkg.inputattribs.ig import ig\n",
    "from ig_pkg.inputattribs.baseline_generator import get_baseline_generator\n",
    "\n",
    "from ig_pkg.misc import process_heatmap, normalize_tensor, convert_to_img, label_to_class, tran, na_imshow\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip\n",
      "[Train #0] Loss: 8.4526 Acc: 0.0395% Time: 35.4661s\n",
      "[Train #1] Loss: 7.7940 Acc: 0.9089% Time: 71.2390s\n",
      "[Train #2] Loss: 7.0296 Acc: 4.7287% Time: 107.3937s\n",
      "[Train #3] Loss: 6.2181 Acc: 12.7107% Time: 143.7977s\n",
      "[Train #4] Loss: 5.4099 Acc: 23.7355% Time: 180.4143s\n",
      "[Train #5] Loss: 4.6099 Acc: 36.3541% Time: 216.4243s\n",
      "[Train #6] Loss: 3.8152 Acc: 49.9078% Time: 252.1479s\n",
      "[Train #7] Loss: 3.0492 Acc: 63.3562% Time: 288.0173s\n",
      "[Train #8] Loss: 2.3572 Acc: 75.2107% Time: 324.2294s\n",
      "[Train #9] Loss: 1.7414 Acc: 84.6681% Time: 360.0335s\n",
      "[Train #10] Loss: 1.2201 Acc: 93.1639% Time: 396.0384s\n",
      "[Train #11] Loss: 0.8040 Acc: 98.2745% Time: 431.8322s\n",
      "[Train #12] Loss: 0.4969 Acc: 99.7761% Time: 467.9667s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ig_pkg.loss.focal_loss import FocalLoss\n",
    "from ig_pkg.loss.metrics import ArcMarginProduct, AddMarginProduct\n",
    "import torchvision.models as models\n",
    "\n",
    "device=\"cuda:0\"\n",
    "train_dataset, valid_dataset = get_datasets(name= 'celebAHQ_whole', data_path = '/root/data/whole') # 3819,2398 \n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features # 512\n",
    "model.fc = nn.Linear(num_features, 3819) # multi-class classification (num_of_class == 307)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 30\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "\n",
    "    # load a batch data of images\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "    if epoch_acc > 99: break\n",
    "\n",
    "save_path = f'/root/pretrained/celebahq_whole_flip.pth'\n",
    "torch.save(model.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip\n",
      "[Train #0] Loss: 7.3216 Acc: 1.6690% Time: 104.6927s\n",
      "[Train #1] Loss: 5.5499 Acc: 11.7503% Time: 210.6489s\n",
      "[Train #2] Loss: 3.9619 Acc: 29.8465% Time: 308.8367s\n",
      "[Train #3] Loss: 2.7269 Acc: 49.8036% Time: 407.9734s\n",
      "[Train #4] Loss: 1.8144 Acc: 66.9538% Time: 513.0342s\n",
      "[Train #5] Loss: 1.1648 Acc: 80.8729% Time: 617.6198s\n",
      "[Train #6] Loss: 0.7369 Acc: 89.1423% Time: 722.1929s\n",
      "[Train #7] Loss: 0.4588 Acc: 94.5064% Time: 827.2891s\n",
      "[Train #8] Loss: 0.2678 Acc: 97.6214% Time: 931.3937s\n",
      "[Train #9] Loss: 0.1543 Acc: 99.0628% Time: 1038.3805s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ig_pkg.loss.focal_loss import FocalLoss\n",
    "from ig_pkg.loss.metrics import ArcMarginProduct, AddMarginProduct\n",
    "import torchvision.models as models\n",
    "\n",
    "device=\"cuda:0\"\n",
    "train_dataset, valid_dataset = get_datasets(name= 'celebAHQ_5', data_path = '/root/data/train') # 3819,2398 \n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features # 512\n",
    "model.fc = nn.Linear(num_features, 2398) # multi-class classification (num_of_class == 307)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 30\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "\n",
    "    # load a batch data of images\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "    if epoch_acc > 99: break\n",
    "        \n",
    "save_path = f'/root/pretrained/celebahq_train_flip.pth'\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip\n",
      "[Train #0] Loss: 8.2136 Acc: 1.1600% Time: 147.1768s\n",
      "[Train #1] Loss: 6.6772 Acc: 7.7500% Time: 276.9724s\n",
      "[Train #2] Loss: 5.3267 Acc: 19.8033% Time: 417.5162s\n",
      "[Train #3] Loss: 4.1686 Acc: 34.1200% Time: 558.7775s\n",
      "[Train #4] Loss: 3.2264 Acc: 47.7167% Time: 700.2342s\n",
      "[Train #5] Loss: 2.4480 Acc: 59.7633% Time: 839.9531s\n",
      "[Train #6] Loss: 1.8121 Acc: 70.5167% Time: 969.7769s\n",
      "[Train #7] Loss: 1.2896 Acc: 79.4267% Time: 1099.5536s\n",
      "[Train #8] Loss: 0.8690 Acc: 87.0167% Time: 1239.1792s\n",
      "[Train #9] Loss: 0.5616 Acc: 92.6433% Time: 1369.0747s\n",
      "[Train #10] Loss: 0.3361 Acc: 97.0133% Time: 1500.3617s\n",
      "[Train #11] Loss: 0.1942 Acc: 99.0900% Time: 1639.3315s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ig_pkg.loss.focal_loss import FocalLoss\n",
    "from ig_pkg.loss.metrics import ArcMarginProduct, AddMarginProduct\n",
    "import torchvision.models as models\n",
    "\n",
    "device=\"cuda:0\"\n",
    "train_dataset, valid_dataset = get_datasets(name= 'celebAHQ_5', data_path = '/root/data/identity_celebahq') # 3819,2398 \n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "# np.save('/root/data/celebahq_identity/identity_original.npy', class_names)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features # 512\n",
    "model.fc = nn.Linear(num_features, 6217) \n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 30\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "\n",
    "    # load a batch data of images\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "    if epoch_acc > 99: break\n",
    "        \n",
    "save_path = f'/root/pretrained/celebahq_original_{epoch_acc}.pth'\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip\n",
      "[Train #0] Loss: 8.2226 Acc: 0.9433% Time: 130.2989s\n",
      "[Train #1] Loss: 6.7668 Acc: 6.8633% Time: 261.0708s\n",
      "[Train #2] Loss: 5.4323 Acc: 18.3667% Time: 392.4425s\n",
      "[Train #3] Loss: 4.2724 Acc: 32.9167% Time: 523.3748s\n",
      "[Train #4] Loss: 3.3012 Acc: 46.5333% Time: 653.9012s\n",
      "[Train #5] Loss: 2.5012 Acc: 59.0767% Time: 783.5817s\n",
      "[Train #6] Loss: 1.8478 Acc: 70.0500% Time: 914.2168s\n",
      "[Train #7] Loss: 1.3232 Acc: 78.8067% Time: 1051.4545s\n",
      "[Train #8] Loss: 0.8940 Acc: 86.6667% Time: 1183.8315s\n",
      "[Train #9] Loss: 0.5820 Acc: 92.2900% Time: 1324.8905s\n",
      "[Train #10] Loss: 0.3470 Acc: 96.9033% Time: 1457.5039s\n",
      "[Train #11] Loss: 0.1978 Acc: 99.1067% Time: 1589.2342s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ig_pkg.loss.focal_loss import FocalLoss\n",
    "from ig_pkg.loss.metrics import ArcMarginProduct, AddMarginProduct\n",
    "import torchvision.models as models\n",
    "\n",
    "device=\"cuda:0\"\n",
    "train_dataset, valid_dataset = get_datasets(name= 'celebAHQ_5', data_path = '/root/data/identity_celebahq') # 3819,2398 \n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "# np.save('/root/data/celebahq_identity/identity_original.npy', class_names)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features # 512\n",
    "model.fc = nn.Linear(num_features, 6217) \n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 30\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "\n",
    "    # load a batch data of images\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "    if epoch_acc > 99: break\n",
    "        \n",
    "save_path = f'/root/pretrained/celebahq_original_flip.pth'\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMy8G3IL+8++WTZ/K7SQBqo",
   "collapsed_sections": [],
   "name": "CelebAMask HQ Dataset Processing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dh",
   "language": "python",
   "name": "dh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
