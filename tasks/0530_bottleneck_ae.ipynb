{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4AJbOdjZd4Qq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ig_pkg.datasets import get_datasets\n",
    "\n",
    "from ig_pkg.models.generator import get_model\n",
    "from ig_pkg.models.classifier import get_classifier\n",
    "from ig_pkg.models.pretrained_models import get_pretrained_model\n",
    "\n",
    "from ig_pkg.inputattribs.ig import make_interpolation, ig\n",
    "from ig_pkg.inputattribs.baseline_generator import get_baseline_generator\n",
    "\n",
    "from ig_pkg.misc import process_heatmap, normalize_tensor, convert_to_img, convert_mask_img, label_to_class, tran, na_imshow\n",
    "\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ig_pkg.loss.focal_loss import FocalLoss\n",
    "from ig_pkg.loss.metrics import ArcMarginProduct, AddMarginProduct\n",
    "\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "my_cmap=plt.cm.seismic(np.arange(plt.cm.seismic.N))\n",
    "device = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/dh1/lib/python3.8/site-packages/torch/serialization.py:779: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "CIFAR10_STATS = {\n",
    "    'mean' : [0.4914, 0.4822, 0.4465],\n",
    "    'std' : [0.2023, 0.1994, 0.2010]\n",
    "}\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(), \n",
    "                T.Normalize(CIFAR10_STATS['mean'], CIFAR10_STATS['std'])\n",
    "            ])\n",
    "\n",
    "valid_dataset = torchvision.datasets.CIFAR10(root='/data8/donghun/cifar10/untracked/', train=False, transform=transform)\n",
    "# valid_dataset = torchvision.datasets.CIFAR10(root='/root/data/cifar10', train=False, transform=transform)\n",
    "# interpolation = torch.from_numpy(np.load('/root/results/cifar10/image_simple_gradient_ascent_interpolation.npy'))\n",
    "\n",
    "classifier = torch.load(\"/data8/donghun/cifar10/results/densenet/script_model.pt\",  map_location='cpu').eval().to(device)\n",
    "# model = torch.load(\"/root/data/cifar10/cifar10/results/densenet/script_model.pt\",  map_location='cpu').eval().to('cuda:0')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottelneck AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'BottleneckAE' on <module 'bottleneck_ae' (namespace)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m../bottleneck_ae/results/model_best.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m, map_location\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# bottle = torch.load(\"/data8/donghun/cifar10/bottleneck_ae/results/model_best.pt\", map_location='cpu')#.eval().to(device)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# model = torch.load(\"/home/dhlee/code/ig_inversion/bottleneck_ae/results/model_best.pt\", map_location='cpu').eval().to(device)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# inputs = torch.randn(1, 1, 32, 32)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# print(\"bottlenekc:\", (info['bottleneck']))\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# print(\"decode:\",  model.decode(info['bottleneck']).size())\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dh1/lib/python3.8/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    788\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 789\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    791\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dh1/lib/python3.8/site-packages/torch/serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1130\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1131\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1133\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1135\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/dh1/lib/python3.8/site-packages/torch/serialization.py:1124\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m mod_name \u001b[39m=\u001b[39m load_module_mapping\u001b[39m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m-> 1124\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfind_class(mod_name, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'BottleneckAE' on <module 'bottleneck_ae' (namespace)>"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"../bottleneck_ae/results/model_best.pt\", map_location='cpu')\n",
    "\n",
    "# bottle = torch.load(\"/data8/donghun/cifar10/bottleneck_ae/results/model_best.pt\", map_location='cpu')#.eval().to(device)\n",
    "# model = torch.load(\"/home/dhlee/code/ig_inversion/bottleneck_ae/results/model_best.pt\", map_location='cpu').eval().to(device)\n",
    "# inputs = torch.randn(1, 1, 32, 32)\n",
    "# outputs = model(inputs)\n",
    "# x_hat, loss_dict, info = outputs \n",
    "\n",
    "# print(\"input: \", inputs.size())\n",
    "# print(\"bottlenekc:\", (info['bottleneck']))\n",
    "# print(\"decode:\",  model.decode(info['bottleneck']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "names = {\n",
    "    'zero',\n",
    "    'one',\n",
    "    'min',\n",
    "    'max',\n",
    "    'scalar',\n",
    "#     'encoder',\n",
    "#     'optimizer',\n",
    "#     'hybrid',\n",
    "    'gaussian_blur',\n",
    "    'gaussian',\n",
    "    'uniform',\n",
    "    'maximumdistance' \n",
    "}\n",
    "\n",
    "# {'gaussian',\n",
    "#  'gaussian_blur',\n",
    "#  'max',\n",
    "#  'maximumdistance',\n",
    "#  'min',\n",
    "#  'one',\n",
    "#  'scalar',\n",
    "#  'uniform',\n",
    "#  'zero'}\n",
    "\n",
    "index = 0 \n",
    "# x,y = valid_datasets[index]\n",
    "x = ferrot_tensor\n",
    "y = 359\n",
    "\n",
    "fig, axes = plt.subplots(2, (len(names)//2)+1, figsize=(2*len(names)//2, 2*2))\n",
    "axes_flat = axes.flat \n",
    "my_cmap=plt.cm.seismic(np.arange(plt.cm.seismic.N))\n",
    "\n",
    "ax = next(axes_flat)\n",
    "ax.imshow(convert_to_img(x))\n",
    "\n",
    "AOPC = []\n",
    "LODDs = []\n",
    "Kendal = []\n",
    "for name in names:\n",
    "    print(name)\n",
    "    a = []\n",
    "    b = []\n",
    "    try:\n",
    "        b_generator =  get_baseline_generator(name, scalar = 0.3)\n",
    "        baseline = b_generator(x=x,y=y)\n",
    "\n",
    "    except Exception as e: \n",
    "        print(\"-----\")\n",
    "        print(\"fail:\", name)\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "    attr = ig(eval_mode.to(device), x, y, baseline, device=device)\n",
    "    Kendal.append(kendal_correlation(eval_mode, ferrot_tensor, baseline, attr.detach().cpu().numpy(), device))\n",
    "\n",
    "#     print(name)\n",
    "    for i in range(19):\n",
    "#         k = i * 5 + 5        \n",
    "        k = i + 1\n",
    "        aopc, lodds = pipeline(eval_mode, ferrot_tensor.to(device), baseline, attr, k, device, name)\n",
    "        \n",
    "#         print(name, k, aopc, lodds)\n",
    "        a.append(aopc)\n",
    "        b.append(lodds)\n",
    "    \n",
    "    attr, kwargs  = process_heatmap(attr.cpu(), my_cmap)\n",
    "    ax = next(axes_flat)\n",
    "    ax.imshow(attr, **kwargs)\n",
    "    ax.set_title(name)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    AOPC.append(a)\n",
    "    LODDs.append(b)    \n",
    "    \n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMy8G3IL+8++WTZ/K7SQBqo",
   "collapsed_sections": [],
   "name": "CelebAMask HQ Dataset Processing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dh1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
